{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04202f9-c6a8-4af6-bf05-da93b648cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATASETS CLEANING #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d513e72-ad13-4f3c-ad3b-22efb2d082d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned_Customers.csv saved.\n",
      "Cleaned_Exchange_Rates.csv saved.\n",
      "Cleaned_Products.csv saved.\n",
      "Cleaned_Sales.csv saved.\n",
      "Cleaned_Stores.csv saved.\n",
      "All datasets cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to clean dataframe\n",
    "def clean_dataframe(df, date_columns=[]):\n",
    "    # Standardize column names: Replace spaces with underscores\n",
    "    df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "    # Handle date columns: Convert and format correctly\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Replace problematic values (NaN, NaT, empty strings) with None\n",
    "    df.replace({np.nan: None, \"nan\": None, \"NaT\": None, \"\": None}, inplace=True)\n",
    "    \n",
    "    # Convert all columns to appropriate types\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].apply(lambda x: None if pd.isna(x) or x == \"nan\" else x.strip() if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Convert NaN values in numeric columns to None (MySQL NULL)\n",
    "    df = df.where(pd.notna(df), None)\n",
    "\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "# List of datasets with required cleaning steps\n",
    "datasets = {\n",
    "    \"Customers\": {\"drop_cols\": [\"State_Code\", \"Zip_Code\", \"Continent\"], \"date_cols\": [\"Birthday\"]},\n",
    "    \"Exchange_Rates\": {\"drop_cols\": [], \"date_cols\": [\"Date\"]},\n",
    "    \"Products\": {\"drop_cols\": [\"SubcategoryKey\"], \"date_cols\": []},\n",
    "    \"Sales\": {\"drop_cols\": [], \"date_cols\": [\"Order_Date\", \"Delivery_Date\"]},\n",
    "    \"Stores\": {\"drop_cols\": [], \"date_cols\": [\"Open_Date\"]}\n",
    "}\n",
    "\n",
    "# Process each dataset\n",
    "for name, config in datasets.items():\n",
    "    df = pd.read_csv(f\"{name}.csv\", encoding=\"ANSI\")\n",
    "    \n",
    "    # Replace spaces in column names before dropping any columns\n",
    "    df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "    # Drop specified columns if they exist\n",
    "    df.drop(columns=[col for col in config[\"drop_cols\"] if col in df.columns], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # Clean the dataframe\n",
    "    df = clean_dataframe(df, date_columns=config[\"date_cols\"])\n",
    "\n",
    "    # Additional cleaning for specific datasets\n",
    "    if name == \"Products\":\n",
    "        df[\"Unit_Cost_USD\"] = df[\"Unit_Cost_USD\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").str.strip().astype(float)\n",
    "        df[\"Unit_Price_USD\"] = df[\"Unit_Price_USD\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").str.strip().astype(float)\n",
    "    if name == \"Stores\":\n",
    "        df[\"Square_Meters\"] = df[\"Square_Meters\"].fillna(0)\n",
    "    if name == \"Sales\":\n",
    "        df.loc[:, \"Delivery_Date\"] = df[\"Delivery_Date\"].fillna(np.nan)  # Avoids chained assignment issue\n",
    "\n",
    "    # Save cleaned CSV\n",
    "    df.to_csv(f\"Cleaned_{name}.csv\", index=False)\n",
    "    print(f\"Cleaned_{name}.csv saved.\")\n",
    "\n",
    "print(\"All datasets cleaned successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f28d9-066e-48b4-a055-53db6e443264",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MERGING ALL DATASETS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bac375c-b1cc-4cb0-8db5-8f0cbaea382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'Merged_Dataset.csv'\n",
      "   Order_Number  Line_Item  Order_Date Delivery_Date  CustomerKey  StoreKey  \\\n",
      "0        366000          1  2016-01-01          None       265598        10   \n",
      "1        366000          1  2016-01-01          None       265598        10   \n",
      "2        366000          1  2016-01-01          None       265598        10   \n",
      "3        366000          1  2016-01-01          None       265598        10   \n",
      "4        366000          1  2016-01-01          None       265598        10   \n",
      "\n",
      "   ProductKey  Quantity Currency_Code Gender          Name    City    State  \\\n",
      "0        1304         1           CAD   Male  Tyler Vaught  London  Ontario   \n",
      "1        1304         1           CAD   Male  Tyler Vaught  London  Ontario   \n",
      "2        1304         1           CAD   Male  Tyler Vaught  London  Ontario   \n",
      "3        1304         1           CAD   Male  Tyler Vaught  London  Ontario   \n",
      "4        1304         1           CAD   Male  Tyler Vaught  London  Ontario   \n",
      "\n",
      "  Country    Birthday                     Product_Name    Brand  Color  \\\n",
      "0  Canada  1971-03-23  Contoso Lens Adapter M450 White  Contoso  White   \n",
      "1  Canada  1971-03-23  Contoso Lens Adapter M450 White  Contoso  White   \n",
      "2  Canada  1971-03-23  Contoso Lens Adapter M450 White  Contoso  White   \n",
      "3  Canada  1971-03-23  Contoso Lens Adapter M450 White  Contoso  White   \n",
      "4  Canada  1971-03-23  Contoso Lens Adapter M450 White  Contoso  White   \n",
      "\n",
      "   Unit_Cost_USD  Unit_Price_USD                       Subcategory  \\\n",
      "0          31.27            68.0  Cameras & Camcorders Accessories   \n",
      "1          31.27            68.0  Cameras & Camcorders Accessories   \n",
      "2          31.27            68.0  Cameras & Camcorders Accessories   \n",
      "3          31.27            68.0  Cameras & Camcorders Accessories   \n",
      "4          31.27            68.0  Cameras & Camcorders Accessories   \n",
      "\n",
      "   CategoryKey                Category  Square_Meters   Open_Date Currency  \\\n",
      "0            4  Cameras and camcorders         1210.0  2015-04-04      USD   \n",
      "1            4  Cameras and camcorders         1210.0  2015-04-04      CAD   \n",
      "2            4  Cameras and camcorders         1210.0  2015-04-04      AUD   \n",
      "3            4  Cameras and camcorders         1210.0  2015-04-04      EUR   \n",
      "4            4  Cameras and camcorders         1210.0  2015-04-04      GBP   \n",
      "\n",
      "   Exchange  \n",
      "0    1.0000  \n",
      "1    1.3884  \n",
      "2    1.3683  \n",
      "3    0.9185  \n",
      "4    0.6742  \n",
      "Columns: ['Order_Number', 'Line_Item', 'Order_Date', 'Delivery_Date', 'CustomerKey', 'StoreKey', 'ProductKey', 'Quantity', 'Currency_Code', 'Gender', 'Name', 'City', 'State', 'Country', 'Birthday', 'Product_Name', 'Brand', 'Color', 'Unit_Cost_USD', 'Unit_Price_USD', 'Subcategory', 'CategoryKey', 'Category', 'Square_Meters', 'Open_Date', 'Currency', 'Exchange']\n",
      "        Order_Number  Line_Item  Order_Date Delivery_Date  CustomerKey  \\\n",
      "0             366000          1  2016-01-01          None       265598   \n",
      "1             366000          1  2016-01-01          None       265598   \n",
      "2             366000          1  2016-01-01          None       265598   \n",
      "3             366000          1  2016-01-01          None       265598   \n",
      "4             366000          1  2016-01-01          None       265598   \n",
      "...              ...        ...         ...           ...          ...   \n",
      "314415       2243032          3  2021-02-20    2021-02-23       331277   \n",
      "314416       2243032          3  2021-02-20    2021-02-23       331277   \n",
      "314417       2243032          3  2021-02-20    2021-02-23       331277   \n",
      "314418       2243032          3  2021-02-20    2021-02-23       331277   \n",
      "314419       2243032          3  2021-02-20    2021-02-23       331277   \n",
      "\n",
      "        StoreKey  ProductKey  Quantity Currency_Code Gender              Name  \\\n",
      "0             10        1304         1           CAD   Male      Tyler Vaught   \n",
      "1             10        1304         1           CAD   Male      Tyler Vaught   \n",
      "2             10        1304         1           CAD   Male      Tyler Vaught   \n",
      "3             10        1304         1           CAD   Male      Tyler Vaught   \n",
      "4             10        1304         1           CAD   Male      Tyler Vaught   \n",
      "...          ...         ...       ...           ...    ...               ...   \n",
      "314415         0         464         7           CAD   Male  William Rochelle   \n",
      "314416         0         464         7           CAD   Male  William Rochelle   \n",
      "314417         0         464         7           CAD   Male  William Rochelle   \n",
      "314418         0         464         7           CAD   Male  William Rochelle   \n",
      "314419         0         464         7           CAD   Male  William Rochelle   \n",
      "\n",
      "           City    State Country    Birthday                     Product_Name  \\\n",
      "0        London  Ontario  Canada  1971-03-23  Contoso Lens Adapter M450 White   \n",
      "1        London  Ontario  Canada  1971-03-23  Contoso Lens Adapter M450 White   \n",
      "2        London  Ontario  Canada  1971-03-23  Contoso Lens Adapter M450 White   \n",
      "3        London  Ontario  Canada  1971-03-23  Contoso Lens Adapter M450 White   \n",
      "4        London  Ontario  Canada  1971-03-23  Contoso Lens Adapter M450 White   \n",
      "...         ...      ...     ...         ...                              ...   \n",
      "314415  Calgary  Alberta  Canada  1993-05-25     Proseware LCD22W M2001 Black   \n",
      "314416  Calgary  Alberta  Canada  1993-05-25     Proseware LCD22W M2001 Black   \n",
      "314417  Calgary  Alberta  Canada  1993-05-25     Proseware LCD22W M2001 Black   \n",
      "314418  Calgary  Alberta  Canada  1993-05-25     Proseware LCD22W M2001 Black   \n",
      "314419  Calgary  Alberta  Canada  1993-05-25     Proseware LCD22W M2001 Black   \n",
      "\n",
      "            Brand  Color  Unit_Cost_USD  Unit_Price_USD  \\\n",
      "0         Contoso  White          31.27            68.0   \n",
      "1         Contoso  White          31.27            68.0   \n",
      "2         Contoso  White          31.27            68.0   \n",
      "3         Contoso  White          31.27            68.0   \n",
      "4         Contoso  White          31.27            68.0   \n",
      "...           ...    ...            ...             ...   \n",
      "314415  Proseware  Black         224.97           679.0   \n",
      "314416  Proseware  Black         224.97           679.0   \n",
      "314417  Proseware  Black         224.97           679.0   \n",
      "314418  Proseware  Black         224.97           679.0   \n",
      "314419  Proseware  Black         224.97           679.0   \n",
      "\n",
      "                             Subcategory  CategoryKey                Category  \\\n",
      "0       Cameras & Camcorders Accessories            4  Cameras and camcorders   \n",
      "1       Cameras & Camcorders Accessories            4  Cameras and camcorders   \n",
      "2       Cameras & Camcorders Accessories            4  Cameras and camcorders   \n",
      "3       Cameras & Camcorders Accessories            4  Cameras and camcorders   \n",
      "4       Cameras & Camcorders Accessories            4  Cameras and camcorders   \n",
      "...                                  ...          ...                     ...   \n",
      "314415                          Monitors            3               Computers   \n",
      "314416                          Monitors            3               Computers   \n",
      "314417                          Monitors            3               Computers   \n",
      "314418                          Monitors            3               Computers   \n",
      "314419                          Monitors            3               Computers   \n",
      "\n",
      "        Square_Meters   Open_Date Currency  Exchange  \n",
      "0              1210.0  2015-04-04      USD    1.0000  \n",
      "1              1210.0  2015-04-04      CAD    1.3884  \n",
      "2              1210.0  2015-04-04      AUD    1.3683  \n",
      "3              1210.0  2015-04-04      EUR    0.9185  \n",
      "4              1210.0  2015-04-04      GBP    0.6742  \n",
      "...               ...         ...      ...       ...  \n",
      "314415            0.0  2010-01-01      USD    1.0000  \n",
      "314416            0.0  2010-01-01      CAD    1.2610  \n",
      "314417            0.0  2010-01-01      AUD    1.2723  \n",
      "314418            0.0  2010-01-01      EUR    0.8238  \n",
      "314419            0.0  2010-01-01      GBP    0.7126  \n",
      "\n",
      "[314420 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned datasets\n",
    "customers = pd.read_csv(\"Cleaned_Customers.csv\")\n",
    "exchange_rates = pd.read_csv(\"Cleaned_Exchange_Rates.csv\")\n",
    "products = pd.read_csv(\"Cleaned_Products.csv\")\n",
    "sales = pd.read_csv(\"Cleaned_Sales.csv\")\n",
    "stores = pd.read_csv(\"Cleaned_Stores.csv\")\n",
    "\n",
    "# Convert necessary columns to datetime format and format them for MySQL (YYYY-MM-DD)\n",
    "sales[\"Order_Date\"] = pd.to_datetime(sales[\"Order_Date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "exchange_rates[\"Date\"] = pd.to_datetime(exchange_rates[\"Date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Merge datasets\n",
    "df = (\n",
    "    sales\n",
    "    .merge(customers, on=\"CustomerKey\", how=\"inner\")\n",
    "    .merge(products, on=\"ProductKey\", how=\"inner\")\n",
    "    .merge(stores, on=\"StoreKey\", how=\"inner\")\n",
    ")\n",
    "\n",
    "# Merge with exchange rates (left join to keep all sales records)\n",
    "merge_keys = [\"Order_Date\"]\n",
    "if \"Currency\" in df.columns and \"Currency\" in exchange_rates.columns:\n",
    "    merge_keys.append(\"Currency\")\n",
    "\n",
    "df = df.merge(exchange_rates, left_on=merge_keys, right_on=[\"Date\"] + merge_keys[1:], how=\"left\")\n",
    "\n",
    "# Clean up columns\n",
    "df.drop(columns=[\"State_y\", \"Country_y\", \"Date\"], inplace=True, errors=\"ignore\")\n",
    "df.rename(columns={\"State_x\": \"State\", \"Country_x\": \"Country\"}, inplace=True)\n",
    "\n",
    "# **Replace problematic values with None (MySQL NULL)**\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].apply(lambda x: None if pd.isna(x) or x in [\"nan\", \"NaT\", \"\"] else x.strip() if isinstance(x, str) else x)\n",
    "    else:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # Convert invalid numeric values to NaN\n",
    "df = df.where(pd.notna(df), None)  # Convert NaN to None\n",
    "\n",
    "# **Rename columns to replace spaces with underscores**\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "# **Remove duplicates**\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save and display results\n",
    "df.to_csv(\"Merged_Dataset.csv\", index=False)\n",
    "print(\"Merged dataset saved as 'Merged_Dataset.csv'\")\n",
    "print(df.head())\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Display all columns for better readability\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c37f78-0258-4bab-9613-723ed422ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATABASE AND TABLES CREATION AND INSERTION #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a3ac7a-1a46-460b-a46e-7702145a1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database and tables created successfully.\n",
      "Processing Cleaned_Customers.csv → Customers...\n",
      "Customers inserted successfully.\n",
      "Processing Cleaned_Exchange_Rates.csv → Exchange_Rates...\n",
      "Exchange_Rates inserted successfully.\n",
      "Processing Cleaned_Products.csv → Products...\n",
      "Products inserted successfully.\n",
      "Processing Cleaned_Sales.csv → Sales...\n",
      "Sales inserted successfully.\n",
      "Processing Cleaned_Stores.csv → Stores...\n",
      "Stores inserted successfully.\n",
      "Processing Merged_Dataset.csv → Merged_Dataset...\n",
      "Merged_Dataset inserted successfully.\n",
      "\n",
      "Tables in Data_Spark: ['customers', 'exchange_rates', 'merged_dataset', 'products', 'sales', 'stores']\n",
      "MySQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "# Read database credentials from config.ini\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")  # Ensure this file is present in the working directory\n",
    "\n",
    "host = config[\"mysql\"][\"host\"]\n",
    "user = config[\"mysql\"][\"user\"]\n",
    "password = config[\"mysql\"][\"password\"]\n",
    "database = \"Data_Spark\"  # Fixed database name as required\n",
    "\n",
    "# Connect to MySQL server (without specifying database to create it first)\n",
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create Database\n",
    "cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {database};\")\n",
    "cursor.execute(f\"USE {database};\")\n",
    "\n",
    "# **Table Creation Queries**\n",
    "tables = {\n",
    "    \"Customers\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Customers (\n",
    "            CustomerKey INT PRIMARY KEY,\n",
    "            Gender VARCHAR(10),\n",
    "            Name VARCHAR(255),\n",
    "            City VARCHAR(100),\n",
    "            State VARCHAR(100),\n",
    "            Country VARCHAR(100),\n",
    "            Birthday DATE\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"Exchange_Rates\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Exchange_Rates (\n",
    "            Date DATE,\n",
    "            Currency VARCHAR(10),\n",
    "            Exchange DECIMAL(10,4),\n",
    "            PRIMARY KEY (Date, Currency)\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"Products\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Products (\n",
    "            ProductKey INT PRIMARY KEY,\n",
    "            Product_Name VARCHAR(255),\n",
    "            Brand VARCHAR(100),\n",
    "            Color VARCHAR(50),\n",
    "            Unit_Cost_USD DECIMAL(10,2),\n",
    "            Unit_Price_USD DECIMAL(10,2),\n",
    "            Subcategory VARCHAR(100),\n",
    "            CategoryKey INT,\n",
    "            Category VARCHAR(100)\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"Sales\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Sales (\n",
    "            Order_Number INT,\n",
    "            Line_Item INT,\n",
    "            Order_Date DATE,\n",
    "            Delivery_Date DATE,\n",
    "            CustomerKey INT,\n",
    "            StoreKey INT,\n",
    "            ProductKey INT,\n",
    "            Quantity INT,\n",
    "            Currency_Code VARCHAR(10),\n",
    "            PRIMARY KEY (Order_Number, Line_Item)\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"Stores\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Stores (\n",
    "            StoreKey INT PRIMARY KEY,\n",
    "            Country VARCHAR(100),\n",
    "            State VARCHAR(100),\n",
    "            Square_Meters DECIMAL(10,2),\n",
    "            Open_Date DATE\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"Merged_Dataset\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Merged_Dataset (\n",
    "            CustomerKey INT,\n",
    "            Gender VARCHAR(10),\n",
    "            Name VARCHAR(255),\n",
    "            City VARCHAR(100),\n",
    "            State VARCHAR(100),\n",
    "            Country VARCHAR(100),\n",
    "            Birthday DATE,\n",
    "            Order_Number INT,\n",
    "            Line_Item INT,\n",
    "            Order_Date DATE,\n",
    "            Delivery_Date DATE,\n",
    "            StoreKey INT,\n",
    "            ProductKey INT,\n",
    "            Quantity INT,\n",
    "            Currency_Code VARCHAR(10),\n",
    "            Product_Name VARCHAR(255),\n",
    "            Brand VARCHAR(100),\n",
    "            Color VARCHAR(50),\n",
    "            Unit_Cost_USD DECIMAL(10,2),\n",
    "            Unit_Price_USD DECIMAL(10,2),\n",
    "            Subcategory VARCHAR(100),\n",
    "            CategoryKey INT,\n",
    "            Category VARCHAR(100),\n",
    "            Square_Meters DECIMAL(10,2),\n",
    "            Open_Date DATE,\n",
    "            Currency VARCHAR(10),\n",
    "            Exchange DECIMAL(10,4)\n",
    "        );\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Execute table creation queries\n",
    "for table_name, query in tables.items():\n",
    "    cursor.execute(query)\n",
    "\n",
    "connection.commit()\n",
    "print(\"✅ Database and tables created successfully.\")\n",
    "\n",
    "# **Function to Load and Insert Data**\n",
    "def load_and_insert_data(csv_file, table_name):\n",
    "    print(f\"Processing {csv_file} → {table_name}...\")\n",
    "    \n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # **Fix column names (replace spaces with underscores)**\n",
    "    df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "    \n",
    "    # **Convert NaN, NaT, empty strings to None (MySQL NULL)**\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].apply(lambda x: None if pd.isna(x) or x in [\"nan\", \"NaT\", \"\"] else x.strip() if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.where(pd.notna(df), None)\n",
    "\n",
    "    # **Remove Duplicates**\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # **Convert DataFrame to Tuple Format**\n",
    "    data_tuples = [tuple(x) for x in df.itertuples(index=False, name=None)]\n",
    "    \n",
    "    # **Create Insert Query**\n",
    "    columns = \", \".join(df.columns)\n",
    "    placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "    insert_query = f\"INSERT IGNORE INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "    # **Insert Data into MySQL**\n",
    "    cursor.executemany(insert_query, data_tuples)\n",
    "    connection.commit()\n",
    "    print(f\"{table_name} inserted successfully.\")\n",
    "\n",
    "# **Load and Insert Data from CSV Files**\n",
    "csv_table_mapping = {\n",
    "    \"Cleaned_Customers.csv\": \"Customers\",\n",
    "    \"Cleaned_Exchange_Rates.csv\": \"Exchange_Rates\",\n",
    "    \"Cleaned_Products.csv\": \"Products\",\n",
    "    \"Cleaned_Sales.csv\": \"Sales\",\n",
    "    \"Cleaned_Stores.csv\": \"Stores\",\n",
    "    \"Merged_Dataset.csv\": \"Merged_Dataset\"\n",
    "}\n",
    "\n",
    "for csv_file, table_name in csv_table_mapping.items():\n",
    "    load_and_insert_data(csv_file, table_name)\n",
    "\n",
    "# **Verify Tables**\n",
    "cursor.execute(\"SHOW TABLES;\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"\\nTables in Data_Spark:\", [t[0] for t in tables])\n",
    "\n",
    "# **Close Connection**\n",
    "cursor.close()\n",
    "connection.close()\n",
    "print(\"MySQL connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251bf270-b944-4214-aec3-d8421ea719aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
